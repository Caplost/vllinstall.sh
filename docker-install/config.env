# vllm+Ray 多机多卡部署配置文件
# 修改此文件中的变量以自定义部署

#=====================
# 基础配置
#=====================
# 基础镜像
BASE_IMAGE="image.sourcefind.cn:5000/dcu/admin/base/pytorch:2.3.0-ubuntu22.04-dtk24.04.3-py3.10"

# 容器名称前缀
CONTAINER_PREFIX="vllm-ray"

# 共享内存大小
SHM_SIZE="500g"

# 项目路径(在宿主机上)
PROJECT_PATH="/path/to/your/project"

# 模型存储路径(在宿主机上)
MODEL_PATH="/path/to/models"

# HYHAL路径(如适用)
HYHAL_PATH="/opt/hyhal"

#=====================
# 网络配置
#=====================
# Ray端口
RAY_PORT="6379"

# Ray Dashboard端口
DASHBOARD_PORT="8265"

# API服务端口
API_PORT="8000"

#=====================
# 性能配置
#=====================
# 默认Tensor并行大小(0表示自动使用所有可用GPU)
DEFAULT_TP_SIZE="0"

# 批处理大小
DEFAULT_BATCH_SIZE="4"

# 量化配置(none, int8, int4)
QUANTIZATION="none"

#=====================
# 模型配置
#=====================
# 默认模型名称(将从MODEL_PATH中加载)
DEFAULT_MODEL="your-model-name"

# 模型下载来源(huggingface, modelscope, custom)
MODEL_SOURCE="huggingface"

# 是否使用本地缓存
USE_LOCAL_CACHE="true"

# HuggingFace令牌(如需要)
HF_TOKEN=""

#=====================
# 高级配置
#=====================
# 是否使用KV缓存
USE_KV_CACHE="true"

# 是否启用流式响应
ENABLE_STREAMING="true"

# 日志级别(debug, info, warning, error)
LOG_LEVEL="info"

# 是否自动重启服务
AUTO_RESTART="true"

# 是否在启动时验证模型
VALIDATE_MODEL="true"