# DeepSeek R1 INT8 Model Deployment

This repository contains a Python script for deploying the DeepSeek R1 INT8 quantized model on an existing Ray cluster with tensor parallelism across multiple GPUs.

## Overview

The `deploy_deepseek_r1_int8.py` script simplifies deploying DeepSeek's R1 INT8 model by:

- Connecting to your existing Ray cluster
- Installing all required dependencies
- Handling multiple import patterns for DeepSeek modules
- Setting up tensor parallelism across 16 GPUs
- Deploying a REST API service with Ray Serve

## Requirements

- Python 3.8+
- Existing Ray cluster with 16 GPUs (64GB VRAM each)
- DeepSeek R1 INT8 model files in `/home/models/DeepSeek-R1-Channel-INT8` (or specified path)

## Quick Start

```bash
# Deploy with default settings
python deploy_deepseek_r1_int8.py

# Deploy with dependency installation
python deploy_deepseek_r1_int8.py --install_deps

# Deploy with custom model path
python deploy_deepseek_r1_int8.py --model_path /path/to/model --install_deps

# Run diagnostics before deployment
python deploy_deepseek_r1_int8.py --debug --install_deps
```

## Usage Options

```
usage: deploy_deepseek_r1_int8.py [-h] [--model_path MODEL_PATH] [--tensor_parallel_size TENSOR_PARALLEL_SIZE]
                                  [--host HOST] [--port PORT] [--max_batch_size MAX_BATCH_SIZE]
                                  [--max_input_length MAX_INPUT_LENGTH] [--max_output_length MAX_OUTPUT_LENGTH]
                                  [--ray_address RAY_ADDRESS] [--install_deps] [--cache_dir CACHE_DIR] [--debug]
```

### Model Arguments

- `--model_path`: Path to the DeepSeek R1 INT8 model (default: `/home/models/DeepSeek-R1-Channel-INT8`)
- `--tensor_parallel_size`: Number of GPUs to use for tensor parallelism (default: 16)

### Server Arguments

- `--host`: Host to bind the server to (default: `0.0.0.0`)
- `--port`: Port to bind the server to (default: 8000)

### Generation Arguments

- `--max_batch_size`: Maximum batch size for inference (default: 32)
- `--max_input_length`: Maximum input sequence length (default: 4096)
- `--max_output_length`: Maximum output sequence length (default: 4096)

### Ray Cluster Arguments

- `--ray_address`: Ray cluster address to connect to (default: "auto")

### Other Arguments

- `--install_deps`: Install dependencies before deployment
- `--cache_dir`: Directory to cache model weights
- `--debug`: Enable debug mode with detailed diagnostics

## Connecting to a Specific Ray Cluster

If your Ray cluster is running at a specific address, you can specify it:

```bash
python deploy_deepseek_r1_int8.py --ray_address "ray://192.168.1.100:10001"
```

## Making API Requests

After deployment, you can interact with the model through the REST API:

```bash
# Basic request
curl -X POST http://localhost:8000 \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Once upon a time", "max_new_tokens": 512, "temperature": 0.7}'

# Custom generation parameters
curl -X POST http://localhost:8000 \
     -H "Content-Type: application/json" \
     -d '{
           "prompt": "Write a short story about AI",
           "max_new_tokens": 1024,
           "temperature": 0.8,
           "top_p": 0.95,
           "top_k": 50,
           "repetition_penalty": 1.2
         }'
```

## API Response Format

```json
{
  "generated_text": "... generated text here ...",
  "input_tokens": 10,
  "generated_tokens": 512,
  "generation_time": 5.2,
  "tokens_per_second": 98.5
}
```

## Troubleshooting

### Missing Dependencies

If you encounter errors related to missing packages, use the `--install_deps` flag:

```bash
python deploy_deepseek_r1_int8.py --install_deps
```

### DeepSeek Module Import Issues

The script tries multiple import patterns for DeepSeek modules. If you still encounter issues, check:

```bash
python deploy_deepseek_r1_int8.py --debug
```

### Insufficient GPU Resources

If your Ray cluster has fewer than 16 GPUs, the script will warn you and ask if you want to continue.

### Checking Ray Cluster Status

Use Ray's built-in tools to check your cluster status:

```bash
ray status
```

## Advanced Configuration

For advanced customization, you can modify the `model_deployment.py` file that's generated by the script. This file contains the Ray Serve deployment class and model loading logic.

## License

This deployment script is provided as-is. The DeepSeek model is subject to its own license terms. 